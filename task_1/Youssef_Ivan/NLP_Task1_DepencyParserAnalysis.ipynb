{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7E0HZKwXDCLC"
   },
   "outputs": [],
   "source": [
    "!pip install treetaggerwrapper\n",
    "!pip install spacy\n",
    "!pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Urs71pN7TAvS"
   },
   "outputs": [],
   "source": [
    "!pip install stanza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5dT_bmjPF7q"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "G8YINlzCPOWj"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "\n",
    "nlp =en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "95fu7dRrHkQ_"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "def read_text(path_to_text: str) -> str:\n",
    "\n",
    "    with open(path_to_text, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    return text.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "def read_text_splitted(path_to_text: str) -> str:\n",
    "\n",
    "    text = []\n",
    "\n",
    "    with open(path_to_text, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line_clean = line.replace(\"\\n\", \"\")\n",
    "            if len(line_clean) < 2:\n",
    "                continue\n",
    "            text.append(line_clean)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> list:\n",
    "\n",
    "    text_full = \" \".join(text)\n",
    "    text_full_clean = \"\".join(\n",
    "        [i for i in text_full if i not in string.punctuation.replace(\".\", \"\").replace(\"!\", \"\") + \"”\"]\n",
    "    )\n",
    "    text_full_clean = (\n",
    "        text_full_clean.replace(\"That’ll\", \"That will\")\n",
    "        .replace(\"Potter’s\", \"Potter is\")\n",
    "        .replace(\"Voldy’s\", \"Voldy has\")\n",
    "        .replace(\"let’s\", \"let us\")\n",
    "    )\n",
    "\n",
    "    return text_full, text_full_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "9hcHVZElTVns"
   },
   "outputs": [],
   "source": [
    "sentences=read_text_splitted('./Harry_en.txt')\n",
    "last_5_sent_full, last_5_sent_full_clean = clean_text(sentences[-5:])\n",
    "words=last_5_sent_full_clean.replace(\".\",\"\").split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrgPhLvsUjx0"
   },
   "source": [
    "### Pattern Dependency Parsing:\n",
    "Issue: it seems to only recognize Nsubj and Obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XAVAW5pYGoHR"
   },
   "outputs": [],
   "source": [
    "from pattern.en import parse\n",
    "from pattern.en import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pWraGVaIVE4",
    "outputId": "2a50f57a-5c48-4d47-adef-644b14860476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA   \n",
      "                                                             \n",
      "           The   DT     NP      SBJ    1      -      -       \n",
      "          bang   NN     NP ^    SBJ    1      -      -       \n",
      "           was   VBD    VP      -      1      -      -       \n",
      "          like   IN     PP      -      -      PNP    -       \n",
      "             a   DT     NP      -      -      PNP    -       \n",
      "        cannon   NN     NP ^    -      -      PNP    -       \n",
      "         blast   NN     NP ^    -      -      PNP    -       \n",
      "           and   CC     -       -      -      -      -       \n",
      "           the   DT     NP      -      -      -      -       \n",
      "        golden   JJ     NP ^    -      -      -      -       \n",
      "        flames   NNS    NP ^    -      -      -      -       \n",
      "          that   WDT    -       -      -      -      -       \n",
      "       erupted   VBD    VP      -      -      -      -       \n",
      "       between   IN     PP      -      -      PNP    -       \n",
      "          them   PRP    NP      -      -      PNP    -       \n",
      "            at   IN     PP      -      -      PNP    -       \n",
      "           the   DT     NP      -      -      PNP    -       \n",
      "          dead   JJ     NP ^    -      -      PNP    -       \n",
      "        center   NN     NP ^    -      -      PNP    -       \n",
      "            of   IN     PP      -      -      PNP    -       \n",
      "           the   DT     NP      SBJ    2      PNP    -       \n",
      "        circle   NN     NP ^    SBJ    2      PNP    -       \n",
      "          they   PRP    NP ^    SBJ    2      PNP    -       \n",
      "           had   VBD    VP      -      2      -      -       \n",
      "          been   VBN    VP ^    -      2      -      -       \n",
      "      treading   VBG    VP ^    -      2      -      -       \n",
      "        marked   VBN    VP ^    -      2      -      -       \n",
      "           the   DT     NP      OBJ    2      -      -       \n",
      "         point   NN     NP ^    OBJ    2      -      -       \n",
      "         where   WRB    -       -      -      -      -       \n",
      "           the   DT     NP      SBJ    3      -      -       \n",
      "        spells   NNS    NP ^    SBJ    3      -      -       \n",
      "      collided   VBD    VP      -      3      -      -       \n",
      "             .   .      -       -      -      -      -       \n",
      "\n",
      "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA   \n",
      "                                                             \n",
      "         Harry   NNP    NP      SBJ    1      -      -       \n",
      "           saw   VBD    VP      -      1      -      -       \n",
      "     Voldemort   NN     NP      OBJ    1      -      -       \n",
      "             ’   ''     -       -      -      -      -       \n",
      "             s   JJ     NP      SBJ    2      -      -       \n",
      "         green   JJ     NP ^    SBJ    2      -      -       \n",
      "           jet   NN     NP ^    SBJ    2      -      -       \n",
      "          meet   VB     VP      -      2      -      -       \n",
      "           his   PRP$   NP      OBJ    2      -      -       \n",
      "           own   MD     VP      -      3      -      -       \n",
      "         spell   VB     VP ^    -      3      -      -       \n",
      "           saw   VBD    VP ^    -      3      -      -       \n",
      "           the   DT     NP      OBJ    3      -      -       \n",
      "         Elder   NNP    NP ^    OBJ    3      -      -       \n",
      "          Wand   NNP    NP ^    OBJ    3      -      -       \n",
      "           fly   VBP    VP      -      4      -      -       \n",
      "          high   JJ     NP      OBJ    4      -      -       \n",
      "          dark   NN     NP ^    OBJ    4      -      -       \n",
      "       against   IN     PP      -      -      PNP    -       \n",
      "           the   DT     NP      -      -      PNP    -       \n",
      "       sunrise   NN     NP ^    -      -      PNP    -       \n",
      "      spinning   NN     NP ^    -      -      PNP    -       \n",
      "        across   IN     PP      -      -      -      -       \n",
      "           the   DT     -       -      -      -      -       \n",
      "     enchanted   VBN    VP      -      5      -      -       \n",
      "       ceiling   NN     NP      OBJ    5      -      -       \n",
      "          like   IN     PP      -      -      PNP    -       \n",
      "           the   DT     NP      -      -      PNP    -       \n",
      "          head   NN     NP ^    -      -      PNP    -       \n",
      "            of   IN     PP      -      -      PNP    -       \n",
      "        Nagini   NNP    NP      SBJ    6      PNP    -       \n",
      "      spinning   VBG    VP      -      6      PNP    -       \n",
      "       through   IN     PP      -      -      PNP    -       \n",
      "           the   DT     NP      -      -      PNP    -       \n",
      "           air   NN     NP ^    -      -      PNP    -       \n",
      "        toward   IN     PP      -      -      PNP    -       \n",
      "           the   DT     NP      SBJ    7      PNP    -       \n",
      "        master   NN     NP ^    SBJ    7      PNP    -       \n",
      "            it   PRP    NP ^    SBJ    7      PNP    -       \n",
      "         would   MD     VP      -      7      -      -       \n",
      "           not   RB     VP ^    -      7      -      -       \n",
      "          kill   VB     VP ^    -      7      -      -       \n",
      "           who   WP     -       -      -      -      -       \n",
      "           had   VBD    VP      -      8      -      -       \n",
      "          come   VBN    VP ^    -      8      -      -       \n",
      "            to   TO     VP ^    -      8      -      -       \n",
      "          take   VB     VP ^    -      8      -      -       \n",
      "          full   JJ     NP      OBJ    8      -      -       \n",
      "    possession   NN     NP ^    OBJ    8      -      -       \n",
      "            of   IN     PP      -      -      PNP    -       \n",
      "            it   PRP    NP      -      -      PNP    -       \n",
      "            at   IN     PP      -      -      -      -       \n",
      "          last   JJ     ADJP    -      -      -      -       \n",
      "             .   .      -       -      -      -      -       \n",
      "\n",
      "          WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA   \n",
      "                                                             \n",
      "           And   CC     -       -      -      -      -       \n",
      "         Harry   NNP    NP      -      -      -      -       \n",
      "          with   IN     PP      -      -      PNP    -       \n",
      "           the   DT     NP      -      -      PNP    -       \n",
      "      unerring   JJ     NP ^    -      -      PNP    -       \n",
      "         skill   NN     NP ^    -      -      PNP    -       \n",
      "            of   IN     PP      -      -      PNP    -       \n",
      "           the   DT     NP      SBJ    1      PNP    -       \n",
      "        Seeker   NNP    NP ^    SBJ    1      PNP    -       \n",
      "        caught   VBD    VP      -      1      -      -       \n",
      "           the   DT     NP      OBJ    1      -      -       \n",
      "          wand   NN     NP ^    OBJ    1      -      -       \n",
      "            in   IN     PP      -      -      PNP    -       \n",
      "           his   PRP$   NP      -      -      PNP    -       \n",
      "          free   JJ     NP ^    -      -      PNP    -       \n",
      "          hand   NN     NP ^    -      -      PNP    -       \n",
      "            as   IN     PP      -      -      PNP    -       \n",
      "     Voldemort   NNP    NP      SBJ    2      PNP    -       \n",
      "          fell   VBD    VP      -      2      -      -       \n",
      "      backward   RB     ADVP    -      -      -      -       \n",
      "          arms   NNS    NP      SBJ    3      -      -       \n",
      "       splayed   VBD    VP      -      3      -      -       \n",
      "           the   DT     NP      OBJ    3      -      -       \n",
      "          slit   NN     NP ^    OBJ    3      -      -       \n",
      "        pupils   NNS    NP ^    OBJ    3      -      -       \n",
      "            of   IN     PP      -      -      PNP    -       \n",
      "           the   DT     NP      SBJ    4      PNP    -       \n",
      "       scarlet   JJ     NP ^    SBJ    4      PNP    -       \n",
      "          eyes   NNS    NP ^    SBJ    4      PNP    -       \n",
      "       rolling   VBG    VP      -      4      PNP    -       \n",
      "        upward   RB     ADVP    -      -      -      -       \n",
      "             .   .      -       -      -      -      -       \n"
     ]
    }
   ],
   "source": [
    "pprint(parse(last_5_sent_full_clean,\n",
    "    tokenize=True,      # Split punctuation marks from words?\n",
    "    tags=True,          # Parse part-of-speech tags? (NN, JJ, ...)\n",
    "    chunks=True,        # Parse chunks? (NP, VP, PNP, ...)\n",
    "    relations=True,    # Parse chunk relations? (-SBJ, -OBJ, ...)\n",
    "    lemmata=False,      # Parse lemmata? (ate => eat)\n",
    "    encoding='utf-8',   # Input string encoding.\n",
    "    tagset=None         # Penn Treebank II (default) or UNIVERSAL.\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibHJl8YDUuPr"
   },
   "source": [
    "### Spacy Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxZaJ0ixPQv6",
    "outputId": "7166f461-9e6b-4db3-9c8b-c9de710f8d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The det\n",
      "previous amod\n",
      "master nsubjpass\n",
      "will aux\n",
      "never neg\n",
      "have aux\n",
      "been auxpass\n",
      "defeated ROOT\n",
      ". punct\n",
      "That nsubj\n",
      "will aux\n",
      "be ROOT\n",
      "the det\n",
      "end attr\n",
      "of prep\n",
      "it pobj\n",
      ". punct\n",
      "There expl\n",
      "would aux\n",
      "be ROOT\n",
      "time attr\n",
      "to aux\n",
      "talk relcl\n",
      "later amod\n",
      "hours dobj\n",
      "and cc\n",
      "days conj\n",
      "and cc\n",
      "maybe advmod\n",
      "years ROOT\n",
      "in prep\n",
      "which pobj\n",
      "to aux\n",
      "talk relcl\n",
      ". punct\n",
      "We nsubj\n",
      "did ccomp\n",
      "it dobj\n",
      "we nsubj\n",
      "bashed ROOT\n",
      "them dobj\n",
      "wee compound\n",
      "Potter dobj\n",
      "is ROOT\n",
      "the det\n",
      "one attr\n",
      "And cc\n",
      "Voldy nsubj\n",
      "has aux\n",
      "gone ROOT\n",
      "moldy acomp\n",
      "so advmod\n",
      "now advmod\n",
      "let ROOT\n",
      "us nsubj\n",
      "have ccomp\n",
      "fun dobj\n",
      "! punct\n",
      "But cc\n",
      "it nsubj\n",
      "was ROOT\n",
      "applause attr\n",
      ". punct\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(last_5_sent_full_clean)\n",
    "spc=[]\n",
    "for token in doc:\n",
    "  dep_rel=token.dep_\n",
    "  if dep_rel=='ROOT':\n",
    "    dep_rel='root'\n",
    "  elif dep_rel=='prep':\n",
    "    dep_rel='case'\n",
    "  elif dep_rel=='auxpass':\n",
    "    dep_rel='aux:pass'\n",
    "  elif dep_rel=='nsubjpass':\n",
    "    dep_rel='nsubj:pass'\n",
    "  spc.append(dep_rel)\n",
    "  print(token.text,token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGAomKjBU5nS"
   },
   "source": [
    "### Stanza Dependency Parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-AXiXLeSrFE"
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "stanza.download('en')       # This downloads the English models for the neural pipeline\n",
    "nlp = stanza.Pipeline('en') # This sets up a default neural pipeline in English\n",
    "doc = nlp(last_5_sent_full_clean)\n",
    "# doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDu1INA1kek3",
    "outputId": "588f152a-3ae1-4c5c-d00c-b01318b710b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The : det\n",
      "previous : amod\n",
      "master : nsubj:pass\n",
      "will : aux\n",
      "never : advmod\n",
      "have : aux\n",
      "been : aux:pass\n",
      "defeated : root\n",
      ". : punct\n",
      "That : nsubj\n",
      "will : aux\n",
      "be : cop\n",
      "the : det\n",
      "end : root\n",
      "of : case\n",
      "it : nmod\n",
      ". : punct\n",
      "There : expl\n",
      "would : aux\n",
      "be : root\n",
      "time : nsubj\n",
      "to : mark\n",
      "talk : acl\n",
      "later : amod\n",
      "hours : obj\n",
      "and : cc\n",
      "days : conj\n",
      "and : cc\n",
      "maybe : advmod\n",
      "years : conj\n",
      "in : case\n",
      "which : obl\n",
      "to : mark\n",
      "talk : acl\n",
      ". : punct\n",
      "We : nsubj\n",
      "did : root\n",
      "it : obj\n",
      "we : nsubj\n",
      "bashed : ccomp\n",
      "them : obj\n",
      "wee : mark\n",
      "Potter : nsubj\n",
      "is : cop\n",
      "the : det\n",
      "one : advcl\n",
      "And : cc\n",
      "Voldy : nsubj\n",
      "has : aux\n",
      "gone : conj\n",
      "moldy : xcomp\n",
      "so : advmod\n",
      "now : advmod\n",
      "let : parataxis\n",
      "us : obj\n",
      "have : xcomp\n",
      "fun : obj\n",
      "! : punct\n",
      "But : cc\n",
      "it : nsubj\n",
      "was : cop\n",
      "applause : root\n",
      ". : punct\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "stanz_rels=[]\n",
    "for doc in doc.sentences:\n",
    "  for w in doc.words:\n",
    "    words.append(w.text)\n",
    "    stanz_rels.append(w.deprel)\n",
    "    print(w.text,\":\",w.deprel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJp7RojzVA_z"
   },
   "source": [
    "#### Writing result to file and adding ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "_h0HGq-aiCLY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'words':words,'ground_truth':stanz_rels,'stanza_predictions':stanz_rels,'spacy_predictions':spc})\n",
    "df.to_csv('./token_dependency_labeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNRYbascVGr_"
   },
   "source": [
    "### Comparing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIVa1jUhVKFq",
    "outputId": "5e526c2c-7057-4bf2-a23b-941e812c9d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza Accuracy:  0.9047619047619048 %\n",
      "Spacy Accuracy:  0.6031746031746031 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "results=pd.read_csv('./token_dependency_labeled.csv')\n",
    "print(\"Stanza Accuracy: \",np.mean(results.ground_truth==results.stanza_predictions),'%')\n",
    "print(\"Spacy Accuracy: \",np.mean(results.ground_truth==results.spacy_predictions),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQVX451bXHEW"
   },
   "source": [
    "#### Stanza Error Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZrh2-jeWGbs",
    "outputId": "4f70bbeb-b55f-4e96-da5f-c8c686e89a0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 1, 'obj': 2, 'parataxis': 1, 'relcl': 1, 'root': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "errors=[]\n",
    "for g,s in zip(results.ground_truth,results.stanza_predictions):\n",
    "  if g!=s:\n",
    "    errors.append(g)\n",
    "errors_counter=Counter(errors)\n",
    "dict(errors_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWAAimYFXKF9"
   },
   "source": [
    "#### Spacy Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsHHKopOW89h",
    "outputId": "592d3d2c-5937-4c82-e0e1-4fae0ee44477"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acl': 1,\n",
       " 'advcl': 1,\n",
       " 'ccomp': 1,\n",
       " 'conj': 2,\n",
       " 'cop': 3,\n",
       " 'mark': 3,\n",
       " 'nmod': 1,\n",
       " 'nsubj': 2,\n",
       " 'obj': 7,\n",
       " 'parataxis': 1,\n",
       " 'root': 2,\n",
       " 'xcomp': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "errors=[]\n",
    "for g,s in zip(results.ground_truth,results.spacy_predictions):\n",
    "  if g!=s:\n",
    "    errors.append(g)\n",
    "errors_counter=Counter(errors)\n",
    "dict(errors_counter)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Task1_DepencyParserAnalysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
